# AI와 테스트를 활용한 안정적인 기능 개발 리포트

## 사용하는 도구를 선택한 이유가 있을까요? 각 도구의 특징에 대해 조사해본적이 있나요?

AI 도구로는 **Cursor**를 선택했습니다. 여러 AI 코딩 도구들을 찾아보다가 Cursor로 결정한 이유가 몇 가지 있었습니다.

첫 번째는 **GUI 기반의 직관적인 UX**였습니다. VS Code 기반이라 익숙한 인터페이스에 AI 기능이 자연스럽게 통합되어 있었습니다. 채팅창, 인라인 편집, 커맨드 팔레트 등으로 상황에 맞게 AI를 컨트롤할 수 있는 것이 정말 편했습니다. 특히 `@파일명` 으로 컨텍스트를 바로 지정할 수 있는 기능이 강력했습니다.

두 번째는 **모델 선택의 유연성**이었습니다. Cursor는 내부적으로 GPT-4, Claude Sonnet, Grok 등 여러 AI 모델을 선택할 수 있습니다. 저는 주로 Claude Sonnet 4.5를 사용했는데, 긴 컨텍스트 처리가 필요한 작업에서 특히 좋았습니다. 상황에 따라 모델을 바꿀 수 있다는 것이 큰 장점이었습니다.

세 번째는 **Composer 모드**였습니다. 여러 파일을 동시에 수정해야 할 때, 일반 채팅보다 Composer를 사용하니 훨씬 체계적으로 작업할 수 있었습니다. 특히 통합 테스트 추가하면서 여러 파일 수정할 때 유용했습니다.

다만 완벽하지는 않았습니다. 가끔 컨텍스트를 너무 많이 넣으면 느려지거나(컴퓨터가 세번정도 멈춘..), 원하는 파일만 정확히 수정하지 않는 경우도 있었습니다. 그래도 전반적으로 개발 생산성이 확실히 올라간 것을 체감할 수 있었습니다.

테스팅 도구로는 Vitest, React Testing Library, MSW를 사용했는데, 이는 프로젝트에 이미 세팅되어 있어서 그대로 활용했습니다.

## 테스트를 기반으로 하는 AI를 통한 기능 개발과 없을 때의 기능개발은 차이가 있었나요?

확실히 다릅니다. 테스트 없이 AI에게 "이거 만들어줘" 하면 그럴듯한 코드는 나오는데, 실제로 실행해보면 버그가 있거나 edge case를 제대로 처리하지 못하는 경우가 많았습니다.

하지만 TDD 방식으로 진행하니 결과가 달라졌습니다. RED-GREEN-REFACTOR 사이클을 따라가면서:

1. 먼저 테스트 작성 (실패하는 테스트)
2. 최소한의 구현으로 테스트 통과
3. 리팩토링

이 과정이 AI에게도 명확한 가이드라인이 되었습니다. "이 테스트를 통과시켜줘"라고 요청하면 목표가 분명하여 훨씬 정확한 코드가 나왔습니다.

특히 윤년 29일 규칙이나 31일 규칙 같은 까다로운 로직의 경우, 테스트 케이스를 먼저 작성하니 AI가 놓칠 수 있는 부분을 미리 잡을 수 있었습니다.

## AI의 응답을 개선하기 위해 추가했던 여러 정보(context)는 무엇인가요?

가장 중요했던 것은 PRD(Product Requirements Document)였습니다. 요구사항이 명확하게 문서화되어 있으니 AI가 무엇을 만들어야 하는지 정확히 이해할 수 있었습니다.

그 다음으로는:

- **기존 코드 구조**: 프로젝트의 폴더 구조, 타입 정의(`types.ts`) 같은 것들
- **테스트 예시**: 비슷한 기능의 테스트 코드를 보여주면 스타일을 따라 했습니다
- **에러 로그**: 테스트가 실패하면 에러 메시지 전체를 붙여넣었습니다. 이것이 정말 중요했습니다
- **MUI 가이드라인**: MUI 컴포넌트 테스팅이 까다로워서 별도로 가이드 문서(`mui-guidelines.yaml`)를 만들어 참조시켰습니다

특히 통합 테스트할 때 "Unable to find element" 에러가 계속 발생하여, MUI Select는 `role="combobox"`를 사용해야 한다는 것을 문서화해두니 바로 해결되었습니다.

## 이 context를 잘 활용하게 하기 위해 했던 노력이 있나요?

가장 중요하게 생각한 부분은 **프롬프트 구조화**였습니다. AI에게 작업을 지시할 때 단순히 요청만 하는 것이 아니라, 다음 4가지 요소를 명확히 정의했습니다:

1. **페르소나**: AI가 어떤 역할을 맡을지 (예: TDD 전문가, 테스트 엔지니어)
2. **사전 학습**: 작업 전에 참고해야 할 문서나 가이드라인
3. **행동 규칙**: 지켜야 할 원칙과 제약사항
4. **행동 절차**: 구체적인 단계별 작업 순서

예를 들어, docs 하위의 가이드라인 파일들을 먼저 읽게 한 후 테스트 코드를 작성하도록 했습니다. 이런 구조화된 지시사항을 **YAML 파일 형식**으로 작성하니 AI가 훨씬 쉽게 이해하고 일관성 있게 작업했습니다. 마크다운보다 YAML이 계층 구조와 규칙을 표현하기에 더 명확했습니다.

## 생성된 여러 결과는 만족스러웠나요? AI의 응답을 어떤 기준을 갖고 '평가(evaluation)'했나요?

만족도는 약 70% 정도입니다. 한 번에 완벽하게 되는 경우는 거의 없었고, 2-3번 정도 수정을 요청하면 원하는 결과가 나왔습니다.

평가 기준:

1. **테스트 통과 여부** (가장 중요)
2. **코드 가독성**: 변수명, 함수명이 의미 있는지
3. **타입 안정성**: TypeScript 에러가 없는지
4. **기존 코드 스타일 일관성**: 프로젝트 컨벤션을 따르는지

특히 날짜 계산 로직(`generateYearlyInstances`)에서 `setFullYear`를 사용했다가 Date 객체 자동 보정 때문에 버그가 발생한 적이 있었습니다. 테스트가 있어서 바로 잡을 수 있었지만, 테스트가 없었다면 찾지 못했을 것 같습니다.

나쁜 예시:

```typescript
currentDate.setFullYear(year); // Date 객체 변경됨!
```

좋은 예시:

```typescript
const candidateDate = new Date(year, startMonth, startDay); // 새 객체 생성
```

### 외부 라이브러리 활용 시 비용 문제

특히 **외부 라이브러리 사용 시 많은 컨텍스트 비용**이 발생했습니다. MUI 컴포넌트를 테스트하는 과정에서 "Unable to find element", "Found multiple elements" 같은 에러를 해결하는 데 상당한 시행착오가 있었습니다.

문제의 핵심은 **사전에 라이브러리 사용법을 명확히 문서화하지 않았다는 점**이었습니다. 예를 들어:

- MUI `Select` 컴포넌트가 `role="combobox"`를 사용한다는 것
- `data-testid`를 추가해야 하는 위치
- `within`과 `waitFor`를 함께 사용해야 하는 시점

이러한 정보를 `mui-guidelines.yaml`로 문서화한 이후에는 AI가 정확한 코드를 생성했습니다. **라이브러리 특수사항을 사전에 문서로 만들어 제공하면, 디버깅 비용을 크게 줄일 수 있다**는 것을 배웠습니다.

결론적으로, 외부 라이브러리를 사용할 때는 AI에게 일반적인 사용법만 의존하게 하는 것이 아니라, 프로젝트 특화 가이드라인을 명확히 제공하는 것이 중요합니다.

## AI에게 어떻게 질문하는것이 더 나은 결과를 얻을 수 있었나요? 시도했던 여러 경험을 알려주세요.

처음에는 agent 역할 정의할때 참고할 수 있는 항목들을 많이 넣어 파일을 작성하니 **300줄이 넘어가면서** 여러 문제가 발생했습니다:

1. AI가 문서 전체를 제대로 파악하지 못함
2. 중요한 지시사항이 긴 설명 속에 묻힘
3. 일관성 없는 출력 결과
4. 불필요한 컨텍스트 토큰 소비

### 개선: 구조화된 YAML 문서

문서 형식을 **Markdown에서 YAML로 변경**하고, 내용을 **4가지 핵심 요소로 압축**했습니다:

1. **페르소나(Persona)**: AI가 맡을 역할과 전문성
2. **사전 학습(Knowledge)**: 필수로 알아야 할 도메인 지식
3. **행동 규칙(Rules)**: 지켜야 할 제약사항과 원칙
4. **행동 절차(Procedures)**: 단계별 실행 절차

이후 output은. **300줄 이상의 장황한 문서가 100줄 미만의 구조화된 YAML로 압축**되었고, **오히려 AI의 출력 품질이 향상**되었습니다.

예시 (YAML 구조):

```yaml
persona:
  role: 'TDD 전문 테스트 엔지니어'
  expertise: ['단위 테스트', '통합 테스트', '리팩토링']

knowledge:
  - 'Vitest 테스팅 프레임워크'
  - 'React Testing Library 쿼리 방법'
  - 'MUI 컴포넌트 테스팅 특수사항'

rules:
  - '테스트 케이스를 먼저 작성한다'
  - '하나의 테스트는 하나의 기능만 검증한다'

procedures:
  - step: 'RED - 실패하는 테스트 작성'
  - step: 'GREEN - 최소 구현'
  - step: 'REFACTOR - 코드 개선'
```

핵심은 **정보의 양이 아니라 구조화와 명확성**이었습니다. 짧지만 명확한 지시가 긴 설명보다 훨씬 효과적이었습니다.

## AI에게 지시하는 작업의 범위를 어떻게 잡았나요? 범위를 좁게, 넓게 해보고 결과를 적어주세요. 그리고 내가 생각하는 적절한 단위를 말해보세요.

### 너무 넓게 잡았을 때

"story단위 unit test들이 완료되면 통합테스트를 시작해줘" -> unit test들이 완료된다면 이라는 조건으로 해석하여 모든 story와 unit test들을 context에 넣어 context양이 길어저 원하는 output이 나오지 않음

### 너무 좁게 잡았을 때

"테스트 실패할때마다 문서를 작성하고 그 문서를 기반으로 수정해줘" -> 루프 단위가 너무 작아서 AI가 '전체 목적'을 놓치게 됨

### 적절했던 범위

**Story 단위**가 가장 적절했습니다:

- S01: 매일 반복 기능
- S02: 매주 반복 기능
- S03: 매월 31일 규칙
- S04: 매년 윤일 규칙

각 Story는:

- 단위 테스트 3-5개
- 구현 함수 1-2개
- 20-30분 정도 소요

이 정도면 AI가 집중력을 잃지 않고 잘 따라왔습니다. 그리고 한 Story가 끝날 때마다 테스트를 실행하여 확인하고 다음으로 넘어가니 안전했습니다.

Epic단위로 나눈 story들이 완료될때 Epic기준으로 통합테스트를 동작시키니 원하는 output이 도출되었습니다.

## 동기들에게 공유하고 싶은 좋은 참고자료나 문구가 있었나요? 마음껏 자랑해주세요.

### 1. MUI 컴포넌트 테스팅 가이드

[React: Don't give up on testing when using Material UI with React](https://jskim1991.medium.com/react-dont-give-up-on-testing-when-using-material-ui-with-react-ff737969eec7)

MUI 컴포넌트를 테스트하는 과정에서 가장 큰 도움을 받은 글입니다. `TextField`, `Select`, `Checkbox`, `Dialog`, `Pagination` 등 다양한 MUI 컴포넌트의 테스트 방법을 실제 코드와 함께 보여줍니다.

### 2. React Testing Library 쿼리 우선순위

[Common mistakes with React Testing Library - Kent C. Dodds](https://kentcdodds.com/blog/common-mistakes-with-react-testing-library)

Kent C. Dodds의 이 글은 React Testing Library를 사용할 때 흔히 하는 실수들과 올바른 쿼리 사용법을 다룹니다. 특히 **쿼리 우선순위**에 대한 내용이 중요했습니다:

1. `getByRole` - 가장 우선적으로 사용 (접근성 기반)
2. `getByLabelText` - 폼 요소에 적합
3. `getByPlaceholderText` - 차선책
4. `getByTestId` - 최후의 수단

이 우선순위를 따르면 **접근성이 높고 유지보수하기 쉬운 테스트 코드**를 작성할 수 있습니다. AI에게도 이 원칙을 명시하니 더 나은 테스트 코드를 생성했습니다.

## AI가 잘하는 것과 못하는 것에 대해 고민한 적이 있나요? 내가 생각하는 지점에 대해 작성해주세요.

이번 프로젝트를 진행하면서 AI의 강점과 한계를 명확하게 느꼈습니다.

**AI가 정말 잘했던 부분들**이 있었습니다. 우선 반복적인 테스트 구조 작성 같은 **보일러플레이트 코드**는 정말 빠르고 정확했습니다. 비슷한 패턴의 테스트를 5개, 10개 만들어야 할 때 시간을 많이 절약할 수 있었습니다. 그리고 기존 코드 스타일을 보여주면 그 **패턴을 잘 따라 했습니다**. 변수 네이밍이나 함수 구조 같은 것들을 일관성 있게 유지해줘서 좋았습니다.

또한 PRD나 가이드라인 같은 **문서를 참조하는 능력**도 뛰어났습니다. 명확한 문서만 제공하면 그대로 구현해냈습니다. 에러가 발생했을 때도 스택 트레이스를 보고 문제점을 찾는 **에러 분석 능력**은 꽤 유용했습니다.

반면에 **AI가 어려워하거나 놓치는 부분**도 분명했습니다.

가장 큰 문제는 **Edge case에 대한 직관이 부족**하다는 것이었습니다. 예를 들어 윤년 2월 29일이나 매월 31일 같은 특수한 경우는 제가 테스트 케이스로 명시하지 않으면 AI가 스스로 고려하지 못했습니다. 단순히 "반복 일정 만들어줘" 하면 일반적인 케이스만 처리하고, 2월이나 30일까지만 있는 달 같은 경우는 빠뜨렸습니다.

그리고 **전체 아키텍처나 큰 그림을 설계하는 것**은 여전히 사람이 해야 했습니다. Epic을 어떻게 Story로 나눌지, 테스트 구조를 어떻게 가져갈지 같은 결정은 제가 했고, AI는 그 안에서 구체적인 구현을 담당했습니다.

**MUI 같은 라이브러리의 특수사항**도 문서화해주지 않으면 계속 같은 실수를 반복했습니다. MUI Select가 `role="combobox"`를 사용한다는 것을 문서로 만들어 주기 전까지는 계속 `role="button"`으로 찾으려고 했고, 그때마다 수정을 요청해야 했습니다.

특히 기억에 남는 것은 **Date 객체를 다룰 때**였습니다. JavaScript Date의 mutable한 특성 때문에 예상치 못한 버그가 자주 발생했습니다. AI가 처음에 작성한 코드는 이런 식이었습니다:

```typescript
const date = new Date(2024, 1, 31);
date.setMonth(1); // 의도: 2월 31일 -> 실제: 3월 2일이나 3일이 됨!
```

이런 실수를 여러 번 반복하다가, 명확하게 "Date 객체를 직접 수정하지 말고 새로 생성하라"고 지시했더니 그제야 올바른 코드가 나왔습니다:

```typescript
const date = new Date(2024, 1, Math.min(31, getLastDayOfMonth(2024, 1)));
```

결국 **AI는 명확한 지시와 예시가 있으면 강력하지만, 암묵적인 지식이나 경험에서 나오는 판단은 아직 부족**하다는 걸 느꼈습니다.

## 마지막으로 느낀점에 대해 적어주세요!

솔직히 처음에는 "AI가 있으니까 뭐든 금방 되겠지" 하는 기대가 있었습니다. 근데 막상 해보니 생각보다 제가 할 일이 많더라고요. 요구사항 정리하고, 테스트 케이스 설계하고, 문서 만들고, 에러 분석하고... AI한테 다 맡기는 게 아니라 진짜 "같이" 일하는 느낌이었습니다.

그런데 이게 오히려 좋았던 것 같습니다. 제가 주도권을 쥐고 방향을 잡으면서, AI는 반복 작업이나 구현 디테일을 빠르게 처리해주는 역할 분담이 자연스럽게 이루어졌습니다.

특히 **TDD가 AI와 함께 일할 때 정말 중요하다**는 걸 느꼈습니다. 테스트 케이스가 명확한 요구사항이 되어주니까, AI한테 "이 테스트 통과시켜줘"라고 하면 목표가 분명해서 훨씬 정확한 결과가 나왔습니다. 그냥 "기능 만들어줘" 하는 것보다 몇 배는 효율적이었습니다.

그리고 **문서화의 위력**을 다시 한번 실감했습니다. PRD 같은 요구사항 문서, MUI 테스팅 가이드, 심지어 YAML로 만든 agent 정의서까지... 이런 것들을 만드는 게 처음엔 귀찮았는데, 막상 만들어두니 AI가 그대로 따라 하면서 일관성 있는 코드를 뽑아냈습니다. 결국 "명확한 의사소통"이 핵심이더라고요. 사람끼리 협업할 때랑 똑같습니다.

가장 기억에 남는 건 통합 테스트 디버깅하던 순간이었습니다. MUI 컴포넌트 때문에 "Found multiple elements", "Unable to find" 같은 에러가 계속 나서 정말 답답했습니다. 5번도 넘게 시도하고 수정하고를 반복했는데, 그 과정에서 React Testing Library의 쿼리 우선순위라든지, MUI의 내부 구조라든지... 이런 것들을 제대로 공부하게 되었습니다. 에러가 많이 나서 힘들었지만, 덕분에 실력이 늘은 것 같습니다.
